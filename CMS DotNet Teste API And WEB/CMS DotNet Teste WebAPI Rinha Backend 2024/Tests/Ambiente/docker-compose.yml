version: "3.5"

services:
  api-1:  &api-1
    restart: always
    # Lembre-se de que seu serviço HTTP deve estar hospedado num repositório
    # publicamente acessível! Ex.: hub.docker.com
    container_name: deno-api-1
    image: arrudaricardo/rinha-de-backend-2024-q1:latest
    # Não é necessário expor qualquer porta além da porta do load balancer,
    # mas é comum as pessoas o fazerem para testaremsuas APIs e conectarem
    # ao banco de dados na fase de desenvolvimento.
    # ports:
    #   - "8081:8080"
    expose:
      - 8081
    depends_on:
      - db
    deploy:
      resources:
        limits:
          cpus: "0.60"
          memory: "195MB"

  api-2:
      <<: *api-1
      container_name: deno-api-2
      expose:
        - 8082

  caddy:
    image: caddy:2.7.6-alpine
    restart: unless-stopped
    ports:
        # Obrigatório expor/usar a porta 9999 no load balancer!
      - "9999:8000" 
    volumes:
        - ./Caddyfile:/etc/caddy/Caddyfile
    depends_on:
      - api-1
      - api-2
      - db
    deploy:
      resources:
        limits:
          cpus: "0.10"
          memory: "60MB"
  

  db:
    image: postgres
    container_name: postgres
    environment:
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_DB=postgres
    expose:
      - "5432"
    volumes:
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql:ro,z
    command: postgres -c checkpoint_timeout=600 -c max_wal_size=4096
    deploy:
      resources:
        limits:
          # Note que a soma de todos os limites dos serviços
          # aqui declarados é de 1.5 unidades de CPU e 550MB
          # de memória. A distribuição feita aqui é apenas
          # um exemplo – distribua como quiser.
          cpus: "0.20"
          memory: "100MB"


# O uso do modo `bridge` deve ser adequado à carga que será usada no teste.
# A edição anterior se beneficiou do modo host pois o volume de requisições
# era relativamente alto e a virtualização da rede se tornou um gargalo, mas
# este modo é mais complexo de ser configurado. Fique à vontade para usar o
# modo que quiser desde que não conflite com portas trivialmente usadas em um
# SO.
networks:
  default:
    driver: bridge
    name: rinha-2024q1
    
    
    
    
    
    
    services:
  acerola_db:
    image: postgres:16.1-alpine3.19
    container_name: acerola_db
    environment:
      TZ: America/Sao_Paulo
      POSTGRES_PASSWORD: acerola
    volumes:
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - '5432:5432'
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: '300mb'
  acerola01: &acerola01
    image: ghcr.io/b-sep/acerola:latest
    container_name: acerola01
    depends_on:
      - acerola_db
    deploy:
      resources:
        limits:
          cpus: '0.45'
          memory: '120mb'
  acerola02:
    <<: *acerola01
    container_name: acerola02
  nginx:
    image: nginx:latest
    container_name: acerola_nginx
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - acerola01
      - acerola02
    ports:
      - '9999:9999'
    deploy:
      resources:
        limits:
          cpus: '0.1'
          memory: '10mb'





version: "3.5"

services:
  api-1:  &api-1
    restart: always
    # Lembre-se de que seu serviço HTTP deve estar hospedado num repositório
    # publicamente acessível! Ex.: hub.docker.com
    container_name: deno-api-1
    image: arrudaricardo/rinha-de-backend-2024-q1:latest
    # Não é necessário expor qualquer porta além da porta do load balancer,
    # mas é comum as pessoas o fazerem para testaremsuas APIs e conectarem
    # ao banco de dados na fase de desenvolvimento.
    # ports:
    #   - "8081:8080"
    expose:
      - 8081
    depends_on:
      - db
    deploy:
      resources:
        limits:
          cpus: "0.60"
          memory: "195MB"

  api-2:
      <<: *api-1
      container_name: deno-api-2
      expose:
        - 8082

  caddy:
    image: caddy:2.7.6-alpine
    restart: unless-stopped
    ports:
        # Obrigatório expor/usar a porta 9999 no load balancer!
      - "9999:8000" 
    volumes:
        - ./Caddyfile:/etc/caddy/Caddyfile
    depends_on:
      - api-1
      - api-2
      - db
    deploy:
      resources:
        limits:
          cpus: "0.10"
          memory: "60MB"
  

  db:
    image: postgres
    container_name: postgres
    environment:
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_DB=postgres
    expose:
      - "5432"
    volumes:
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql:ro,z
    command: postgres -c checkpoint_timeout=600 -c max_wal_size=4096
    deploy:
      resources:
        limits:
          # Note que a soma de todos os limites dos serviços
          # aqui declarados é de 1.5 unidades de CPU e 550MB
          # de memória. A distribuição feita aqui é apenas
          # um exemplo – distribua como quiser.
          cpus: "0.20"
          memory: "100MB"


# O uso do modo `bridge` deve ser adequado à carga que será usada no teste.
# A edição anterior se beneficiou do modo host pois o volume de requisições
# era relativamente alto e a virtualização da rede se tornou um gargalo, mas
# este modo é mais complexo de ser configurado. Fique à vontade para usar o
# modo que quiser desde que não conflite com portas trivialmente usadas em um
# SO.
networks:
  default:
    driver: bridge
    name: rinha-2024q1




version: "3.6"

services:
  api01: &api
    image: bgskurono/rinha-gogin:1.1
    hostname: api01
    environment:
      - DB_HOSTNAME=127.0.0.1
      - PORT=3001
      - POOL_MAX=5
      - POOL_MIN=5
    ports:
      - "3001:3001"
    network_mode: host
    depends_on:
      db:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: "0.18"
          memory: "150MB"

  api02:
    <<: *api
    hostname: api02
    environment:
      - DB_HOSTNAME=127.0.0.1
      - PORT=3002
      - POOL_MAX=5
      - POOL_MIN=5
    ports:
      - "3002:3002"

  nginx:
    image: nginx:1.25.3
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - api01
      - api02
    ports:
      - "9999:9999"
    network_mode: host
    deploy:
      resources:
        limits:
          cpus: "0.24"
          memory: "20MB"

  db:
    image: postgres:15.5
    hostname: db
    environment:
      - POSTGRES_PASSWORD=pass
      - POSTGRES_USER=postgres
      - POSTGRES_DB=rinha
    ports:
      - "5432:5432"
    volumes:
      - ./import.sql:/docker-entrypoint-initdb.d/script.sql
    command: postgres -c checkpoint_timeout=600 -c max_wal_size=4096
    network_mode: host
    deploy:
      resources:
        limits:
          cpus: "0.90"
          memory: "230MB"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready"]
      interval: 5s
      timeout: 5s
      retries: 20
      start_period: 10s


version: "3.5"

services:
  api01: &api
    image: devkemc/api-rinha:v1
    # Lembre-se de que seu serviço HTTP deve estar hospedado num repositório
    # publicamente acessível! Ex.: hub.docker.com
    hostname: api01
    environment:
      - HOST_DB=db
      - PORT_DB=5432
      - USER_DB=admin
      - PASSWORD_DB=123
      - DATABASE=rinha
      - MAX_CONNECTION_DB=1
      - PORT=8080

    # Não é necessário expor qualquer porta além da porta do load balancer,
    # mas é comum as pessoas o fazerem para testarem suas APIs e conectarem
    # ao banco de dados na fase de desenvolvimento.
    expose:
      - "8080"
    depends_on:
      - db
    ulimits:
      nproc: 1000000
      nofile:
        soft: 1000000
        hard: 1000000
    deploy:
      resources:
        limits:
          cpus: "0.50"
          memory: "225MB"

  api02:
    <<: *api
    hostname: app2

  nginx:
    image: nginx:latest
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - api01
      - api02
    ports:
      # Obrigatório expor/usar a porta 9999 no load balancer!
      - "9999:9999"
    ulimits:
      nproc: 1000000
      nofile:
        soft: 1000000
        hard: 1000000
    deploy:
      resources:
        limits:
          cpus: "0.40"
          memory: "50MB"

  db:
    image: postgres:latest
    hostname: db
    environment:
      - POSTGRES_PASSWORD=123
      - POSTGRES_USER=admin
      - POSTGRES_DB=rinha
    ports:
      - "5431:5432"
    volumes:
      - ./script.sql:/docker-entrypoint-initdb.d/script.sql
    deploy:
      resources:
        limits:
          # Note que a soma de todos os limites dos serviços
          # aqui declarados é de 1.5 unidades de CPU e 550MB
          # de memória. A distribuição feita aqui é apenas
          # um exemplo – distribua como quiser.
          cpus: "0.10"
          memory: "50MB"

# O uso do modo `bridge` deve ser adequado à carga que será usada no teste.
# A edição anterior se beneficiou do modo host pois o volume de requisições
# era relativamente alto e a virtualização da rede se tornou um gargalo, mas
# este modo é mais complexo de ser configurado. Fique à vontade para usar o
# modo que quiser desde que não conflite com portas trivialmente usadas em um
# SO.
networks:
  default:
    driver: bridge
    name: rinha-nginx-2024q1
